{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c99d009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv', encoding='latin-1')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031216c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns and rename cols\n",
    "\n",
    "data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "\n",
    "data.columns = ['label', 'text']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7444623f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6abcd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data shape\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0131db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check target balance\n",
    "\n",
    "data['label'].value_counts(normalize = True).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5921cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  go jurong point crazy available bugis n great ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...\n",
       "3   ham                u dun say early hor u c already say\n",
       "4   ham                nah think go usf life around though"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# download nltk\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a list text\n",
    "\n",
    "text = list(data['text'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing loop\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corpus = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(text)):\n",
    "\n",
    "    r = re.sub('[^a-zA-Z]', ' ', text[i])\n",
    "\n",
    "    r = r.lower()\n",
    "\n",
    "    r = r.split()\n",
    "\n",
    "    r = [word for word in r if word not in stopwords.words('english')]\n",
    "\n",
    "    r = [lemmatizer.lemmatize(word) for word in r]\n",
    "\n",
    "    r = ' '.join(r)\n",
    "\n",
    "    corpus.append(r)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#assign corpus to data['text']\n",
    "\n",
    "data['text'] = corpus\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47dbdda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data : (3733,)\n",
      "Testing Data :  (1839,)\n"
     ]
    }
   ],
   "source": [
    "# Create Feature and Label sets\n",
    "\n",
    "X = data['text']\n",
    "\n",
    "y = data['label']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train test split (66% train - 33% test)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Training Data :', X_train.shape)\n",
    "\n",
    "print('Testing Data : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3ae0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 5698)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Bag of Words model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "\n",
    "X_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0784cc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', ..., 'ham', 'ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Logistic Regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_cv, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# transform X_test using CV\n",
    "\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# generate predictions\n",
    "\n",
    "predictions = lr.predict(X_test_cv)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad665935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>31</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1600     2\n",
       "spam    31   206"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d343e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
